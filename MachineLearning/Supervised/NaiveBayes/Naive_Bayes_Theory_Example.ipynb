{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c74ca3f",
   "metadata": {},
   "source": [
    "## Introducción Teórica al Algoritmo Naive Bayes\n",
    "\n",
    "El algoritmo **Naive Bayes** es un clasificador probabilístico basado en el **Teorema de Bayes**, ampliamente utilizado por su simplicidad, eficacia y rapidez en problemas de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80b63a4",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. Teorema de Bayes\n",
    "\n",
    "El Teorema de Bayes relaciona las probabilidades condicionales de eventos. Matemáticamente, se expresa como:\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $\\mathbf{P(A|B)}$: Probabilidad posterior de \\(A\\) dado \\(B\\).\n",
    "- $\\mathbf{P(B|A)}$: Probabilidad de \\(B\\) dado \\(A\\) (verosimilitud).\n",
    "- $\\mathbf{P(A)}$: Probabilidad a priori de \\(A\\).\n",
    "- $\\mathbf{P(B)}$: Probabilidad total de \\(B\\).\n",
    "\n",
    "En el contexto de clasificación, \\(A\\) representa una clase y \\(B\\) son los datos observados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a574f",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Suposición de Independencia\n",
    "\n",
    "El término \"Naive\" (ingenuo) proviene de la **suposición de independencia condicional** entre las características. Es decir, se asume que las variables predictoras $X_1, X_2, ..., X_n$ no están correlacionadas entre sí dentro de cada clase. Esto simplifica los cálculos, ya que:\n",
    "\n",
    "$$\n",
    "P(X_1, X_2, ..., X_n|C) = P(X_1|C) \\cdot P(X_2|C) \\cdot ... \\cdot P(X_n|C)\n",
    "$$\n",
    "\n",
    "Aunque esta suposición no siempre se cumple en la práctica, el algoritmo suele funcionar bien en muchos casos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade77c89",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Tipos de Naive Bayes\n",
    "\n",
    "Existen varias versiones de Naive Bayes, dependiendo del tipo de datos:\n",
    "\n",
    "- **Gaussian Naive Bayes**:\n",
    "  - Se utiliza para datos continuos.\n",
    "  - Asume que los valores se distribuyen de manera normal (gaussiana).\n",
    "\n",
    "$$\n",
    "P(X|C) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(X - \\mu)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "- **Multinomial Naive Bayes**:\n",
    "  - Diseñado para datos discretos, como conteos o frecuencias de palabras.\n",
    "- **Bernoulli Naive Bayes**:\n",
    "  - Adecuado para datos binarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91c121d",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. Clasificación\n",
    "\n",
    "Para clasificar un dato, se calcula la probabilidad posterior $P(C_k|X)$ para cada clase $C_k$:\n",
    "\n",
    "## Derivación Matemática del Algoritmo Naive Bayes\n",
    "\n",
    "### 4.1. Contexto General\n",
    "Queremos calcular la probabilidad posterior $P(C_k|X)$, donde:\n",
    "- $C_k$: Una clase específica (por ejemplo, \"Spam\" o \"No Spam\").\n",
    "- $X = \\{X_1, X_2, \\ldots, X_n\\}$: Un conjunto de características observadas.\n",
    "\n",
    "De acuerdo con el **Teorema de Bayes**, se tiene:\n",
    "$$\n",
    "P(C_k|X) = \\frac{P(X|C_k) \\cdot P(C_k)}{P(X)}\n",
    "$$\n",
    "Donde:\n",
    "- $P(C_k)$: Probabilidad a priori de la clase $C_k$.\n",
    "- $P(X|C_k)$: Verosimilitud, o la probabilidad de las características $X$ dado que la clase es $C_k$.\n",
    "- $P(X)$: Probabilidad total de las características $X$.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2. Suposición de Independencia\n",
    "En Naive Bayes, asumimos que las características $X_1, X_2, \\ldots, X_n$ son **independientes condicionalmente** dado la clase $C_k$. Esto significa:\n",
    "$$\n",
    "P(X|C_k) = P(X_1, X_2, \\ldots, X_n|C_k) = P(X_1|C_k) \\cdot P(X_2|C_k) \\cdot \\ldots \\cdot P(X_n|C_k)\n",
    "$$\n",
    "\n",
    "Esta suposición simplifica el cálculo de $P(X|C_k)$, ya que no necesitamos estimar la probabilidad conjunta $P(X_1, X_2, \\ldots, X_n|C_k)$.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3. Sustitución en el Teorema de Bayes\n",
    "Reemplazamos $P(X|C_k)$ en la fórmula original del Teorema de Bayes:\n",
    "$$\n",
    "P(C_k|X) = \\frac{P(C_k) \\cdot P(X_1|C_k) \\cdot P(X_2|C_k) \\cdot \\ldots \\cdot P(X_n|C_k)}{P(X)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4.4. Eliminación del Término $P(X)$\n",
    "El término $P(X)$ es la probabilidad total de las características $X$, calculada como:\n",
    "$$\n",
    "P(X) = \\sum_{C_k} P(X|C_k) \\cdot P(C_k)\n",
    "$$\n",
    "\n",
    "Dado que $P(X)$ es constante para todas las clases $C_k$, podemos ignorarlo al comparar probabilidades relativas entre las clases. Esto nos deja con:\n",
    "$$\n",
    "P(C_k|X) \\propto P(C_k) \\cdot P(X_1|C_k) \\cdot P(X_2|C_k) \\cdot \\ldots \\cdot P(X_n|C_k)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4.5. Clasificación\n",
    "Para clasificar un nuevo ejemplo, calculamos esta probabilidad proporcional para cada clase $C_k$ y seleccionamos la clase con la mayor probabilidad posterior:\n",
    "$$\n",
    "C_{\\text{predicha}} = \\arg\\max_{C_k} \\left[ P(C_k) \\cdot P(X_1|C_k) \\cdot P(X_2|C_k) \\cdot \\ldots \\cdot P(X_n|C_k) \\right]\n",
    "$$\n",
    "\n",
    "De esta forma, el algoritmo asigna al ejemplo la clase $C_k$ más probable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26b6573-3e05-4796-a74c-30c1761df181",
   "metadata": {},
   "source": [
    "### 5. Ventajas y Desventajas\n",
    "\n",
    "**Ventajas:**\n",
    "- Rápido y eficiente, incluso para conjuntos de datos grandes.\n",
    "- Fácil de implementar.\n",
    "- Funciona bien con datos categóricos y texto.\n",
    "\n",
    "**Desventajas:**\n",
    "- La suposición de independencia rara vez se cumple completamente.\n",
    "- Sensible a características irrelevantes o mal representadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd79a022-9f3d-4cf8-9fa9-c4719c99a9c8",
   "metadata": {},
   "source": [
    "### 6. Ejemplo Práctico: Dataset de Correos Electrónicos\n",
    "\n",
    "| ID | Contiene \"Descuento\" | Contiene \"Gratis\" | Contiene \"Urgente\" | Clase     |\n",
    "|----|-----------------------|-------------------|---------------------|-----------|\n",
    "| 1  | Sí                   | Sí                | No                  | Spam      |\n",
    "| 2  | No                   | Sí                | No                  | No Spam   |\n",
    "| 3  | Sí                   | No                | Sí                  | Spam      |\n",
    "| 4  | No                   | No                | No                  | No Spam   |\n",
    "| 5  | Sí                   | Sí                | Sí                  | Spam      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36349317-5826-4ea4-8f95-bb8ed2baa256",
   "metadata": {},
   "source": [
    "---\n",
    "### Clasificación de un Nuevo Correo\n",
    "\n",
    "Dado un correo con las características:\n",
    "\n",
    "- Contiene \"Descuento\": Sí\n",
    "- Contiene \"Gratis\": Sí\n",
    "- Contiene \"Urgente\": No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf9139-887b-40b3-b2b2-dd5e7f3d59e4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Cálculo de Probabilidades\n",
    "\n",
    "#### 1. Probabilidades a Priori\n",
    "\n",
    "Las probabilidades a priori representan la proporción de cada clase en el conjunto de datos:\n",
    "\n",
    "$$P(\\text{Spam}) = \\frac{\\text{Correos Spam}}{\\text{Total de correos}} = \\frac{3}{5} = 0.6$$\n",
    "$$P(\\text{No Spam}) = \\frac{\\text{Correos No Spam}}{\\text{Total de correos}} = \\frac{2}{5} = 0.4$$\n",
    "\n",
    "#### 2. Probabilidades Condicionales\n",
    "\n",
    "**Para la clase Spam:**\n",
    "\n",
    "$$P(\\text{Descuento = Sí} | \\text{Spam}) = \\frac{3}{3} = 1.0$$\n",
    "$$P(\\text{Gratis = Sí} | \\text{Spam}) = \\frac{2}{3} \\approx 0.67$$\n",
    "$$P(\\text{Urgente = No} | \\text{Spam}) = \\frac{1}{3} \\approx 0.33$$\n",
    "\n",
    "**Para la clase No Spam:**\n",
    "\n",
    "$$P(\\text{Descuento = Sí} | \\text{No Spam}) = \\frac{0}{2} = 0.0$$\n",
    "$$P(\\text{Gratis = Sí} | \\text{No Spam}) = \\frac{1}{2} = 0.5$$\n",
    "$$P(\\text{Urgente = No} | \\text{No Spam}) = \\frac{2}{2} = 1.0$$\n",
    "\n",
    "---\n",
    "\n",
    "**Paso 1: Calcular la probabilidad para Spam**\n",
    "\n",
    "$$\n",
    "P(\\text{Spam}|\\text{Características}) \\propto P(\\text{Spam}) \\cdot P(\\text{Descuento = Sí}|\\text{Spam}) \\cdot P(\\text{Gratis = Sí}|\\text{Spam}) \\cdot P(\\text{Urgente = No}|\\text{Spam})\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\text{Spam}|\\text{Características}) \\propto 0.6 \\cdot 1.0 \\cdot 0.67 \\cdot 0.33 \\approx 0.132\n",
    "$$\n",
    "\n",
    "**Paso 2: Calcular la probabilidad para No Spam**\n",
    "\n",
    "$$\n",
    "P(\\text{No Spam}|\\text{Características}) \\propto P(\\text{No Spam}) \\cdot P(\\text{Descuento = Sí}|\\text{No Spam}) \\cdot P(\\text{Gratis = Sí}|\\text{No Spam}) \\cdot P(\\text{Urgente = No}|\\text{No Spam})\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\text{No Spam}|\\text{Características}) \\propto 0.4 \\cdot 0.0 \\cdot 0.5 \\cdot 1.0 = 0.0\n",
    "$$\n",
    "\n",
    "**Resultado:** El correo es clasificado como **Spam**, ya que tiene la mayor probabilidad posterior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
