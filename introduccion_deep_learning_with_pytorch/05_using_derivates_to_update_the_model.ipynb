{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPjy9LpLOgn5zaH8u9LFrU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noodle96/Topicos_Inteligencia_Artificial/blob/main/introduccion_deep_learning_with_pytorch/05_using_derivates_to_update_the_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "EeUmv0jw5JSL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo y descripcion del modelo**"
      ],
      "metadata": {
        "id": "UbSO-Rsg-KTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model and run a forward pass\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(5, 3),\n",
        "    nn.Linear(3, 4),\n",
        "    nn.Linear(4, 2)\n",
        ")\n",
        "\n",
        "print(model)\n",
        "for name, param in model.named_parameters():\n",
        "    print(f'''name: {name}, param: {param}, shape: {param.shape}\\n''')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THFqgsgS5aGc",
        "outputId": "aea2670d-d02d-4563-c042-6a8bc1a07560"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=5, out_features=3, bias=True)\n",
            "  (1): Linear(in_features=3, out_features=4, bias=True)\n",
            "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
            ")\n",
            "name: 0.weight, param: Parameter containing:\n",
            "tensor([[ 0.4423,  0.1999,  0.1287,  0.3831,  0.3197],\n",
            "        [ 0.3443, -0.3235,  0.3015,  0.3319,  0.1389],\n",
            "        [-0.3534, -0.3499, -0.1805, -0.1696,  0.3065]], requires_grad=True), shape: torch.Size([3, 5])\n",
            "\n",
            "name: 0.bias, param: Parameter containing:\n",
            "tensor([-0.0097,  0.1617,  0.4442], requires_grad=True), shape: torch.Size([3])\n",
            "\n",
            "name: 1.weight, param: Parameter containing:\n",
            "tensor([[-0.4676,  0.4952, -0.2614],\n",
            "        [ 0.5773, -0.2147,  0.2956],\n",
            "        [ 0.4218,  0.2232,  0.4242],\n",
            "        [-0.3239,  0.3971, -0.0646]], requires_grad=True), shape: torch.Size([4, 3])\n",
            "\n",
            "name: 1.bias, param: Parameter containing:\n",
            "tensor([-0.5539, -0.1653,  0.5445, -0.2593], requires_grad=True), shape: torch.Size([4])\n",
            "\n",
            "name: 2.weight, param: Parameter containing:\n",
            "tensor([[-0.0764, -0.2164, -0.0269, -0.0999],\n",
            "        [ 0.0263,  0.4291, -0.4516,  0.2194]], requires_grad=True), shape: torch.Size([2, 4])\n",
            "\n",
            "name: 2.bias, param: Parameter containing:\n",
            "tensor([ 0.0789, -0.3873], requires_grad=True), shape: torch.Size([2])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = torch.randn(5)\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzsnTSpd5r8a",
        "outputId": "a85c7050-b6be-441b-8cfb-e9df53d5b634"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.9496, -0.0261,  1.7572,  0.6105, -0.4779])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model(sample)\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZc33uOp-ZJX",
        "outputId": "0084602d-90db-4789-e78c-dd0627228e88"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1728, -0.8254], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_before = model[0].weight.grad\n",
        "print(grad_before) # None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLllOTBA7-wW",
        "outputId": "bd3c4398-f47a-47d7-8381-0c7f23878026"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the loss and compute the gradients\n",
        "criterion = CrossEntropyLoss()\n",
        "target = torch.randn(size=(2,))\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPlVo-618V12",
        "outputId": "c39c672c-b095-4e3d-9f03-a616f2accb90"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.2479, -1.1055])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = criterion(prediction, target)\n",
        "print(loss)\n",
        "loss.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE3AmQ4N-lm9",
        "outputId": "652523ed-5b07-46e2-e604-0785725c3e73"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-1.5281, grad_fn=<DivBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_after = model[0].weight.grad\n",
        "print(grad_after) # None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMau2CX59i8B",
        "outputId": "e6969141-a257-46f7-9a69-8ca1a2ce3a71"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0607, -0.0008,  0.0547,  0.0190, -0.0149],\n",
            "        [ 0.0805,  0.0011, -0.0725, -0.0252,  0.0197],\n",
            "        [ 0.0532,  0.0007, -0.0480, -0.0167,  0.0130]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accedemos a la gradiente de cada capa**"
      ],
      "metadata": {
        "id": "Z8oM0aDg_LCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access each layer's gradients\n",
        "model[0].weight.grad, model[0].bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDKz3nt18Q15",
        "outputId": "92f34462-0730-4f6e-e3a6-88dddc141c3e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0607, -0.0008,  0.0547,  0.0190, -0.0149],\n",
              "         [ 0.0805,  0.0011, -0.0725, -0.0252,  0.0197],\n",
              "         [ 0.0532,  0.0007, -0.0480, -0.0167,  0.0130]]),\n",
              " tensor([ 0.0311, -0.0413, -0.0273]))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model[1].weight.grad, model[1].bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P9L5H4o_Q_V",
        "outputId": "dfe7b0a6-e423-4673-88eb-e4021ae5c26b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0434,  0.0126,  0.0438],\n",
              "         [-0.2726,  0.0789,  0.2751],\n",
              "         [ 0.1794, -0.0519, -0.1810],\n",
              "         [-0.1349,  0.0390,  0.1361]]),\n",
              " tensor([ 0.0762,  0.4783, -0.3147,  0.2366]))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model[2].weight.grad, model[2].bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7MLB-H1_SdS",
        "outputId": "3d95e5b0-8b2f-41a7-e089-a0d58720f1a0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.2639,  0.2666, -0.4334,  0.0343],\n",
              "         [-0.2639, -0.2666,  0.4334, -0.0343]]),\n",
              " tensor([-0.7410,  0.7410]))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Updating model parameter**\n",
        "*   Update the weights by subtracting local gradients scaled by the **learning rate**"
      ],
      "metadata": {
        "id": "AHYlXlTd_ZuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate is typically small\n",
        "lr = 0.001\n",
        "# Update the weights\n",
        "weight = model[0].weight\n",
        "print(\"weight before: \", weight)\n",
        "weight_grad = model[0].weight.grad\n",
        "weight = weight - lr * weight_grad\n",
        "print(\"weight after: \", weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5tetZkd_loS",
        "outputId": "c59245dd-f7f4-46a3-bc45-80119686740f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight before:  Parameter containing:\n",
            "tensor([[ 0.4423,  0.1999,  0.1287,  0.3831,  0.3197],\n",
            "        [ 0.3443, -0.3235,  0.3015,  0.3319,  0.1389],\n",
            "        [-0.3534, -0.3499, -0.1805, -0.1696,  0.3065]], requires_grad=True)\n",
            "weight after:  tensor([[ 0.4423,  0.1999,  0.1286,  0.3830,  0.3197],\n",
            "        [ 0.3442, -0.3235,  0.3016,  0.3319,  0.1388],\n",
            "        [-0.3535, -0.3499, -0.1804, -0.1696,  0.3065]], grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the biases\n",
        "bias = model[0].bias\n",
        "print(\"bias before: \", bias)\n",
        "bias_grad = model[0].bias.grad\n",
        "bias = bias - lr * bias_grad\n",
        "print(\"bias after: \", bias)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXfi4rnA_phL",
        "outputId": "1f2f3a84-59ef-4e91-f41b-28dcc5668753"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bias before:  Parameter containing:\n",
            "tensor([-0.0097,  0.1617,  0.4442], requires_grad=True)\n",
            "bias after:  tensor([-0.0097,  0.1617,  0.4442], grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    }
  ]
}