{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6Sv4Zf+Tv8XdpNUDt8416",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noodle96/Topicos_Inteligencia_Artificial/blob/main/introduccion_deep_learning_with_pytorch/05_using_derivates_to_update_the_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "EeUmv0jw5JSL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo y descripcion del modelo**"
      ],
      "metadata": {
        "id": "UbSO-Rsg-KTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model and run a forward pass\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(5, 3),\n",
        "    nn.Linear(3, 4),\n",
        "    nn.Linear(4, 2)\n",
        ")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THFqgsgS5aGc",
        "outputId": "1a0d4ce2-eb99-4c20-f0c1-d915922ae0d7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=5, out_features=3, bias=True)\n",
            "  (1): Linear(in_features=3, out_features=4, bias=True)\n",
            "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f'''name: {name}, param: {param}, shape: {param.shape}\\n''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNS8BSwox_Iv",
        "outputId": "c5f27cba-0d13-443a-9619-1a76d7bcd7f3"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: 0.weight, param: Parameter containing:\n",
            "tensor([[-0.0839, -0.4413, -0.3870, -0.3310,  0.2520],\n",
            "        [-0.0645, -0.4109,  0.1575, -0.1019,  0.2477],\n",
            "        [ 0.2617, -0.2029,  0.4198, -0.1179, -0.2146]], requires_grad=True), shape: torch.Size([3, 5])\n",
            "\n",
            "name: 0.bias, param: Parameter containing:\n",
            "tensor([ 0.0392, -0.3165, -0.1976], requires_grad=True), shape: torch.Size([3])\n",
            "\n",
            "name: 1.weight, param: Parameter containing:\n",
            "tensor([[-0.0545,  0.2838, -0.3261],\n",
            "        [ 0.2636, -0.4711,  0.3656],\n",
            "        [-0.3387,  0.1374, -0.1095],\n",
            "        [-0.1880, -0.4313, -0.4147]], requires_grad=True), shape: torch.Size([4, 3])\n",
            "\n",
            "name: 1.bias, param: Parameter containing:\n",
            "tensor([-0.2977, -0.1985,  0.0346,  0.2299], requires_grad=True), shape: torch.Size([4])\n",
            "\n",
            "name: 2.weight, param: Parameter containing:\n",
            "tensor([[ 0.4224,  0.4897, -0.4568, -0.1278],\n",
            "        [ 0.0516,  0.1470, -0.0409,  0.3786]], requires_grad=True), shape: torch.Size([2, 4])\n",
            "\n",
            "name: 2.bias, param: Parameter containing:\n",
            "tensor([-0.1815, -0.1792], requires_grad=True), shape: torch.Size([2])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = torch.randn(5)\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzsnTSpd5r8a",
        "outputId": "12112cc9-d4ca-4663-aa17-7e153ad51fc5"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.7776, -0.7555, -2.0096,  1.2856,  0.4624])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">   La variable prediccion va a contener a los w_i_j de los w_i y a los bias b_i"
      ],
      "metadata": {
        "id": "YIst6OnQy8ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model(sample)\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZc33uOp-ZJX",
        "outputId": "7f11f09d-d4fd-4c47-fd58-e0eae2fb7fcd"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3724,  0.0762], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Recordemos que model[i] hace referencia a los **pesos** y **bias** entre la capa[i] y la capa[i+1]"
      ],
      "metadata": {
        "id": "uuKTTRLS2t4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grad_before = model[0].weight.grad\n",
        "print(grad_before) # None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLllOTBA7-wW",
        "outputId": "89ce12ac-7665-4e0d-ff4d-8a545da8a609"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_before_bias = model[0].bias.grad\n",
        "print(grad_before_bias) # None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5r7ptmSyjMv",
        "outputId": "189f42e6-7650-48d3-99b9-bd9c647e38dd"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the loss and compute the gradients\n",
        "criterion = CrossEntropyLoss()\n",
        "target = torch.randn(size=(2,))\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPlVo-618V12",
        "outputId": "e3955bdd-6c89-4ec0-eb7c-2c580f80ca01"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4196,  0.4259])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> la variable loss tambien tiene referencia al modelo porque el atributo prediction tambien hace referencia al modelo"
      ],
      "metadata": {
        "id": "iR1lw19o2Fbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the loss\n",
        "loss = criterion(prediction, target)\n",
        "print(loss)\n",
        "# Compute the gradientd\n",
        "loss.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE3AmQ4N-lm9",
        "outputId": "5e817ff0-786f-43cc-e0bc-48dff0e5a53f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-0.1851, grad_fn=<DivBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_after = model[0].weight.grad\n",
        "print(grad_after)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMau2CX59i8B",
        "outputId": "85d4e445-4964-4238-8867-ba06b1441b85"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2297, -0.0976, -0.2597,  0.1661,  0.0597],\n",
            "        [-0.0788, -0.0335, -0.0891,  0.0570,  0.0205],\n",
            "        [-0.1950, -0.0829, -0.2204,  0.1410,  0.0507]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accedemos a la gradiente de cada capa**"
      ],
      "metadata": {
        "id": "Z8oM0aDg_LCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access each layer's gradients\n",
        "model[0].weight.grad, model[0].bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDKz3nt18Q15",
        "outputId": "a760d775-0186-46af-ba52-e8e82825dd6f"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.2297, -0.0976, -0.2597,  0.1661,  0.0597],\n",
              "         [-0.0788, -0.0335, -0.0891,  0.0570,  0.0205],\n",
              "         [-0.1950, -0.0829, -0.2204,  0.1410,  0.0507]]),\n",
              " tensor([0.1292, 0.0443, 0.1097]))"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model[1].weight.grad, model[1].bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P9L5H4o_Q_V",
        "outputId": "d5d24676-4147-4522-dff4-53b79bc898ac"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.1550, -0.0351, -0.2510],\n",
              "         [ 0.1433, -0.0324, -0.2320],\n",
              "         [-0.1739,  0.0394,  0.2815],\n",
              "         [-0.2117,  0.0479,  0.3428]]),\n",
              " tensor([ 0.1565,  0.1446, -0.1755, -0.2137]))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model[2].weight.grad, model[2].bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7MLB-H1_SdS",
        "outputId": "4935a629-0195-4b78-dfb3-ece5fb1b8e52"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.0455, -0.1765, -0.0659,  0.3400],\n",
              "         [-0.0455,  0.1765,  0.0659, -0.3400]]),\n",
              " tensor([ 0.4220, -0.4220]))"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Updating model parameter**\n",
        "*   Update the weights by subtracting local gradients scaled by the **learning rate**"
      ],
      "metadata": {
        "id": "AHYlXlTd_ZuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate is typically small\n",
        "lr = 0.001\n",
        "# Update the weights\n",
        "weight = model[0].weight\n",
        "print(\"weight before: \", weight)\n",
        "weight_grad = model[0].weight.grad\n",
        "weight = weight - lr * weight_grad\n",
        "print(\"weight after: \", weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5tetZkd_loS",
        "outputId": "d0eb67f4-bb10-4018-fb35-c791252e14f4"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight before:  Parameter containing:\n",
            "tensor([[-0.0839, -0.4413, -0.3870, -0.3310,  0.2520],\n",
            "        [-0.0645, -0.4109,  0.1575, -0.1019,  0.2477],\n",
            "        [ 0.2617, -0.2029,  0.4198, -0.1179, -0.2146]], requires_grad=True)\n",
            "weight after:  tensor([[-0.0837, -0.4412, -0.3867, -0.3311,  0.2520],\n",
            "        [-0.0644, -0.4109,  0.1576, -0.1019,  0.2477],\n",
            "        [ 0.2619, -0.2028,  0.4201, -0.1180, -0.2147]], grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the biases\n",
        "bias = model[0].bias\n",
        "print(\"bias before: \", bias)\n",
        "bias_grad = model[0].bias.grad\n",
        "bias = bias - lr * bias_grad\n",
        "print(\"bias after: \", bias)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXfi4rnA_phL",
        "outputId": "bfc0294b-a696-443a-fc31-1d1bdcb98d33"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bias before:  Parameter containing:\n",
            "tensor([ 0.0392, -0.3165, -0.1976], requires_grad=True)\n",
            "bias after:  tensor([ 0.0391, -0.3165, -0.1977], grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    }
  ]
}