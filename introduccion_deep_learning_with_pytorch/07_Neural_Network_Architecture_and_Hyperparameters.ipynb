{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3T13jjbERSobou88N9orl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noodle96/Topicos_Inteligencia_Artificial/blob/main/introduccion_deep_learning_with_pytorch/07_Neural_Network_Architecture_and_Hyperparameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "9pyxRE-5qtyw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discovering activation functions**"
      ],
      "metadata": {
        "id": "MRTKg8nOq7Hi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The ReLU function activation**"
      ],
      "metadata": {
        "id": "4r3nYHXVrAeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ReLU function with pytorch\n",
        "relu = nn.ReLU()"
      ],
      "metadata": {
        "id": "5Oi7Ni-srI4f"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar relu al vector x y calcular las gradientes\n",
        "x1 = torch.tensor(-10.0, requires_grad=True)\n",
        "x2 = torch.tensor(0.0, requires_grad=True)\n",
        "x3 = torch.tensor(10.0, requires_grad=True)\n",
        "print(x1)\n",
        "print(x2)\n",
        "print(x3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trjJAEYnrUlE",
        "outputId": "69f2a5f3-6d4f-409b-c66b-3494e951e77f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10., requires_grad=True)\n",
            "tensor(0., requires_grad=True)\n",
            "tensor(10., requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = relu(x1)\n",
        "y2 = relu(x2)\n",
        "y3 = relu(x3)\n",
        "print(y1)\n",
        "print(y2)\n",
        "print(y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4s3Qbv0r6aE",
        "outputId": "efb63493-8f76-45f7-ebfb-edc90dab5254"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0., grad_fn=<ReluBackward0>)\n",
            "tensor(0., grad_fn=<ReluBackward0>)\n",
            "tensor(10., grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x1.grad)\n",
        "print(x2.grad)\n",
        "print(x3.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzbMrQVpupaQ",
        "outputId": "7eb5836a-c1eb-4a2b-9a93-4401ec706151"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Ahora veamos las gradientes"
      ],
      "metadata": {
        "id": "MATu4G20xWhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1.backward()\n",
        "y2.backward()\n",
        "y3.backward()"
      ],
      "metadata": {
        "id": "NO8wHWGjs0DY"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x1.grad)\n",
        "print(x2.grad)\n",
        "print(x3.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkCSuqW4uv_r",
        "outputId": "9f1b492e-6008-4b72-e909-fa1fa5e7c928"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.)\n",
            "tensor(0.)\n",
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Leaky ReLU function activation**"
      ],
      "metadata": {
        "id": "SoQQk-9KvCp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFAULT negative_slope = 0.01\n",
        "# 7 to test\n",
        "leaky_relu = nn.LeakyReLU(negative_slope=7)"
      ],
      "metadata": {
        "id": "0s_OxoyyvIPz"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x1 = torch.tensor(-10.0, requires_grad=True)\n",
        "x2 = torch.tensor(0.0, requires_grad=True)\n",
        "x3 = torch.tensor(10.0, requires_grad=True)\n",
        "print(x1)\n",
        "print(x2)\n",
        "print(x3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBmDZq8nvJxn",
        "outputId": "3ff77bc6-d91a-4422-8962-d3d1c61b29f0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10., requires_grad=True)\n",
            "tensor(0., requires_grad=True)\n",
            "tensor(10., requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g1 = leaky_relu(x1)\n",
        "g2 = leaky_relu(x2)\n",
        "g3 = leaky_relu(x3)"
      ],
      "metadata": {
        "id": "73uabc3zvRLQ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(g1)\n",
        "print(g2)\n",
        "print(g3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsrZrytrvUSR",
        "outputId": "83df939b-2dc9-4300-fc7d-6273ee84df3b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-70., grad_fn=<LeakyReluBackward0>)\n",
            "tensor(0., grad_fn=<LeakyReluBackward0>)\n",
            "tensor(10., grad_fn=<LeakyReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Ahora veamos las gradientes"
      ],
      "metadata": {
        "id": "OVb2VuC6xcdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g1.backward()\n",
        "g2.backward()\n",
        "g3.backward()\n",
        "print(x1.grad)\n",
        "print(x2.grad)\n",
        "print(x3.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3umosc0zvhbd",
        "outputId": "d4c9144c-12ac-4cc3-a1f0-e0855454b23f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7.)\n",
            "tensor(7.)\n",
            "tensor(1.)\n"
          ]
        }
      ]
    }
  ]
}